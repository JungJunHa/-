{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"E부문_친환경_1_100.ipynb","provenance":[{"file_id":"1mGg1mbUkqhYiYCNNkupJY0HgZG_TliXJ","timestamp":1632761423492},{"file_id":"1vHClh3eVUisyqJDACTgRVNkM5Cf0qv7c","timestamp":1632675217887},{"file_id":"1WM0kXdVkk6zlpKvHj8WlCs9K_TB9aJE2","timestamp":1632620982490},{"file_id":"1JysrKZirDDDRD700UqoNlwIznSUSk4fY","timestamp":1632531245299}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNGg9Gcc9t+wfpPFFmXOYqD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PG5XGxp_b4va","executionInfo":{"status":"ok","timestamp":1632761528776,"user_tz":-540,"elapsed":26382,"user":{"displayName":"정준하","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04402633433694338869"}},"outputId":"5bdc0cda-7bd7-44da-9d30-fe962be9b435"},"source":["import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","import http\n","\n","drive.mount('/content/drive')\n","\n","# 시가총액 상위 300개 기업리스트 (미래에셋 대우 API 미확인으로, 2021.09.12 기준 시총 상위 300개 기업 사용)\n","lists = pd.read_csv(\"/content/drive/MyDrive/미래에셋/kospi/KOSPI_시가총액_상위500.csv\")\n","lists_1 = lists.loc[0:299]\n","lists_2 = lists_1[['종목명']]\n","\n","\n","# ESG 키워드\n","ESG = {\n","'E_keyword' : ['친환경', '탄소', '에너지'],\n","'S_keyword' : ['캠페인', '교육', '사회'],\n","'G_keyword' : ['위원회', '이사', '지배구조']}\n","ESG_keyword = pd.DataFrame.from_dict(ESG)\n","\n","print(ESG_keyword)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","  E_keyword S_keyword G_keyword\n","0       친환경       캠페인       위원회\n","1        탄소        교육        이사\n","2       에너지        사회      지배구조\n"]}]},{"cell_type":"code","metadata":{"id":"PWUoUliSb5iy"},"source":["# 지난 N개월 간의 종목명 + E 관련 뉴스기사 본문 추출\n","from multiprocessing import Pool\n","from bs4 import BeautifulSoup\n","import datetime\n","from datetime import timedelta\n","import urllib.request\n","from urllib.parse import quote\n","import pandas as pd\n","\n","\n","# 크롤링 메인 함수\n","def get_news(stock, keyword, query, sort, lastpage, period):\n","\n","  stockName = stock\n","  ESGKeyword = keyword\n","\n","  # 크롤링 결과 저장 데이터프레임\n","  news_df = pd.DataFrame(columns=(\"stockName\", \"ESGKeyword\", \"Title\", \"Article\")) \n","\n","  idx = 0\n","\n","\n","  for month in range (0, period): # 해당 검색어(query)로 N(=period)개월치 기사 추출\n","\n","    s_date = datetime.date.today() + timedelta(days = -30 * (month+1))\n","    e_date = datetime.date.today() + timedelta(days = -30 * month)\n","\n","    pageNum = 1\n","\n","    for i in range (1, int(lastpage)*10, 10):\n","      # print(f\"/{pageNum}페이지입니다/\")\n","\n","      url_query = quote(query)\n","      url = f\"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={url_query}&sort=0&photo=0&field=0&pd=6&ds={s_date}&de={e_date}&nso=so:r,p:{period}m,a:all&start={i}\"\n","\n","      search_url = urllib.request.urlopen(url).read()\n","      soup = BeautifulSoup(search_url, 'html.parser')\n","      links = soup.find_all('div', {'class':'info_group'})\n","  \n","\n","      # 하나의 검색 페이지 안에서의 반복\n","      for link in links:\n","\n","        # '네이버 뉴스' 형식으로 작성된 기사만을 추출 (href 2번)\n","        news_urls = link.find_all('a')\n","\n","        if (len(news_urls) == 1): # '네이버 뉴스' 형식 X\n","          continue\n","\n","        else:  # '네이버 뉴스' 형식 O\n","          \n","          for news_url_test in news_urls:\n","            news_url = news_url_test.get('href')\n","\n","          try:\n","            news_link = urllib.request.urlopen(news_url).read()\n","          except (http.client.IncompleteRead) as e:\n","            news_link = e.partial\n","          \n","          news_html = BeautifulSoup(news_link, 'html.parser')\n","\n","          try: \n","            title = news_html.find('h3', {'id': 'articleTitle'}).get_text()\n","            article = news_html.find('div', {'id': 'articleBodyContents'}).get_text()\n","            article = article.replace(\"// flash 오류를 우회하기 위한 함수 추가\", \"\")\n","            article = article.replace(\"function _flash_removeCallback() {}\", \"\")\n","            article = article.replace(\"\\n\",\"\")\n","            article = article.replace(\"\\t\",\"\")\n","\n","            news_df.loc[idx] = [stockName, ESGKeyword, title, article]\n","            idx += 1\n","\n","          except: \n","            pass\n","\n","          # print(\"#\", end=\"\")\n","\n","\n","      pageNum += 1\n","\n","\n","  return news_df\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2neoyHb4Cz3k"},"source":["# E(환경)부문\n","\n","\n","# CONCAT 목적의 초기 데이터프레임 형성\n","default = {\n","'stockName' : ['Test'],\n","'ESGKeyword' : ['Test'],\n","'Title' : ['Test'],\n","'Article' : ['Test']}\n","df_default = pd.DataFrame.from_dict(default) \n","\n","\n","# 파라미터 입력 후 크롤링\n","for i in range(100): #시총 상위 100개 기업\n","\n","  query = lists_2['종목명'].values[i] + \"+\" + ESG_keyword['E_keyword'].values[0]\n","  sort = \"0\" # 관련도 순 기사\n","  lastpage = 100 # 100 페이지까지 크롤링 (최대 400페이지까지 가능하기는 하나, 파일 크기 과부하 방지)\n","  period = 6 # 6개월간의 기사\n","\n","  # print(lists_2['종목명'].values[i])\n","  # print(ESG_keyword['E_keyword'].values[0])\n","  # print(i)\n","  \n","  df = get_news(lists_2['종목명'].values[i], ESG_keyword['E_keyword'].values[0], query, sort, lastpage, period)\n","  df_default = pd.concat([df_default, df], axis = 0)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaCBN-a3BmcC"},"source":["df_default.to_csv('E부문_상위100_친환경.csv', header = True, index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ey6KqbifHB3R"},"source":[""],"execution_count":null,"outputs":[]}]}