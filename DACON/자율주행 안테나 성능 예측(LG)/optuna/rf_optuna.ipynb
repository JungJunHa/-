{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijQBdPY_3ijo",
        "outputId": "b0fba9c7-70c4-45dd-e5b2-d08f13e7be32"
      },
      "id": "ijQBdPY_3ijo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZG-a-o24J4b",
        "outputId": "1a394842-eb9b-4cc1-e2f1-ac4791255aa7"
      },
      "id": "UZG-a-o24J4b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.39)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.9.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "291da8e6",
      "metadata": {
        "id": "291da8e6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import datasets, ensemble\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/DACON/lg_am/'\n",
        "\n",
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')\n",
        "submission = pd.read_csv(path + 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "XMQZa3SJ3zFX"
      },
      "id": "XMQZa3SJ3zFX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df5eb0eb",
      "metadata": {
        "id": "df5eb0eb"
      },
      "outputs": [],
      "source": [
        "target_list = ['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', 'Y_06',\n",
        "       'Y_07', 'Y_08', 'Y_09', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(len(target_list))):\n",
        "    globals()['train_{}'.format(target_list[i])] = train[['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08',\n",
        "       'X_09', 'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17',\n",
        "       'X_18', 'X_19', 'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26',\n",
        "       'X_27', 'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35',\n",
        "       'X_36', 'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44',\n",
        "       'X_45', 'X_46', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53',\n",
        "       'X_54', 'X_55', 'X_56', f'{target_list[i]}']]\n",
        "    # locals()['train_{}'.format(target_list[i])].drop(columns=['X_48', 'X_47', 'X_23', 'X_04'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdFgcv4guPcR",
        "outputId": "c1fd55b1-5dc6-4af2-8feb-48ce1219d1c7"
      },
      "id": "vdFgcv4guPcR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:00<00:00, 157.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y_07"
      ],
      "metadata": {
        "id": "Q9tABoTpXw4l"
      },
      "id": "Q9tABoTpXw4l"
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
        "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
        "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
        "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
        "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
        "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55']"
      ],
      "metadata": {
        "id": "NQ6nxB04dkvm"
      },
      "id": "NQ6nxB04dkvm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ffff27e",
      "metadata": {
        "id": "6ffff27e"
      },
      "outputs": [],
      "source": [
        "X = train_Y_07[feature]\n",
        "y = train_Y_07.loc[:, 'Y_07':]\n",
        "\n",
        "target = test[X.columns]\n",
        "kf = KFold(n_splits = 5, random_state = 42, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_cat(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `CatBoostRegressor` model.\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'criterion' :  'squared_error',\n",
        "        'n_estimators':trial.suggest_int(\"n_estimators\", 30, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth',1, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split',2,30),        \n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,30),    \n",
        "        'min_weight_fraction_leaf' : trial.suggest_uniform('min_weight_fraction_leaf',0.0, 0.5),\n",
        "        'bootstrap' : True,\n",
        "        'oob_score' : True,\n",
        "        'warm_start' : True,\n",
        "        'verbose' : False\n",
        "    }\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        # objective = 'MultiRMSE',\n",
        "        random_state=42,\n",
        "        **params,\n",
        "    )\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "7fiIwTn_4VS-"
      },
      "id": "7fiIwTn_4VS-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_cat, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFbp7pFf6Smc",
        "outputId": "4899725c-bac6-4e3b-e5fb-153b519d7c7a"
      },
      "id": "lFbp7pFf6Smc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-07 10:14:45,153]\u001b[0m A new study created in memory with name: no-name-3a8ab81e-417a-4417-ad06-736288258380\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:15:05,376]\u001b[0m Trial 0 finished with value: 0.41426135481237586 and parameters: {'n_estimators': 319, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 18, 'min_weight_fraction_leaf': 0.3062197855390119}. Best is trial 0 with value: 0.41426135481237586.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:15:45,196]\u001b[0m Trial 1 finished with value: 0.4122040276513959 and parameters: {'n_estimators': 248, 'max_depth': 5, 'min_samples_split': 27, 'min_samples_leaf': 16, 'min_weight_fraction_leaf': 0.10925570170315302}. Best is trial 1 with value: 0.4122040276513959.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:16:34,942]\u001b[0m Trial 2 finished with value: 0.41222686770955563 and parameters: {'n_estimators': 313, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.11563816970208984}. Best is trial 1 with value: 0.4122040276513959.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:16:54,089]\u001b[0m Trial 3 finished with value: 0.4147031956469499 and parameters: {'n_estimators': 346, 'max_depth': 4, 'min_samples_split': 16, 'min_samples_leaf': 15, 'min_weight_fraction_leaf': 0.4836473941951379}. Best is trial 1 with value: 0.4122040276513959.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:17:09,315]\u001b[0m Trial 4 finished with value: 0.41376294226036214 and parameters: {'n_estimators': 179, 'max_depth': 13, 'min_samples_split': 16, 'min_samples_leaf': 6, 'min_weight_fraction_leaf': 0.24875422931852947}. Best is trial 1 with value: 0.4122040276513959.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:18:13,062]\u001b[0m Trial 5 finished with value: 0.41147848882102045 and parameters: {'n_estimators': 313, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 13, 'min_weight_fraction_leaf': 0.07375662914555531}. Best is trial 5 with value: 0.41147848882102045.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:18:34,030]\u001b[0m Trial 6 finished with value: 0.4129199908205171 and parameters: {'n_estimators': 175, 'max_depth': 15, 'min_samples_split': 29, 'min_samples_leaf': 18, 'min_weight_fraction_leaf': 0.1710104141033732}. Best is trial 5 with value: 0.41147848882102045.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:19:42,441]\u001b[0m Trial 7 finished with value: 0.4117286066159256 and parameters: {'n_estimators': 359, 'max_depth': 13, 'min_samples_split': 18, 'min_samples_leaf': 24, 'min_weight_fraction_leaf': 0.08455213567822517}. Best is trial 5 with value: 0.41147848882102045.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:21:22,555]\u001b[0m Trial 8 finished with value: 0.40989812509566964 and parameters: {'n_estimators': 345, 'max_depth': 11, 'min_samples_split': 19, 'min_samples_leaf': 11, 'min_weight_fraction_leaf': 0.034371632632313354}. Best is trial 8 with value: 0.40989812509566964.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:21:35,032]\u001b[0m Trial 9 finished with value: 0.41436801927363043 and parameters: {'n_estimators': 226, 'max_depth': 8, 'min_samples_split': 21, 'min_samples_leaf': 8, 'min_weight_fraction_leaf': 0.33320116237881314}. Best is trial 8 with value: 0.40989812509566964.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:21:37,666]\u001b[0m Trial 10 finished with value: 0.4141370246770744 and parameters: {'n_estimators': 46, 'max_depth': 1, 'min_samples_split': 23, 'min_samples_leaf': 29, 'min_weight_fraction_leaf': 0.01614017074726118}. Best is trial 8 with value: 0.40989812509566964.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "\u001b[32m[I 2022-08-07 10:24:39,465]\u001b[0m Trial 11 finished with value: 0.40706924030732844 and parameters: {'n_estimators': 387, 'max_depth': 15, 'min_samples_split': 11, 'min_samples_leaf': 11, 'min_weight_fraction_leaf': 0.006534141533761029}. Best is trial 11 with value: 0.40706924030732844.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params=study.best_params \n",
        "params['criterion'] = 'squared_error'\n",
        "params['bootstrap'] = True\n",
        "params['oob_score'] = True\n",
        "params['warm_start'] = True\n",
        "params['verbose'] = False"
      ],
      "metadata": {
        "id": "RITzKtqA6TpH"
      },
      "id": "RITzKtqA6TpH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c6f43b",
      "metadata": {
        "id": "25c6f43b"
      },
      "outputs": [],
      "source": [
        "NRMSES = []\n",
        "cb_pred = np.zeros(target.shape[0])\n",
        "for i, idx in enumerate(kf.split(X, y)) :\n",
        "    tr_x, tr_y = X.loc[idx[0]], y.loc[idx[0]]\n",
        "    val_x, val_y = X.loc[idx[1]], y.loc[idx[1]]\n",
        "    \n",
        "    cb = RandomForestRegressor(**params)\n",
        "    cb.fit(tr_x, tr_y)\n",
        "    \n",
        "    val_pred = cb.predict(val_x)\n",
        "    NRMSE = mean_squared_error(val_y, val_pred, squared=False)\n",
        "    print(f\"{i + 1} Fold RMSE = {NRMSE}\")\n",
        "    NRMSES.append(NRMSE)\n",
        "    \n",
        "    fold_pred = cb.predict(target) / kf.n_splits\n",
        "    cb_pred += fold_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8158befe",
      "metadata": {
        "scrolled": true,
        "id": "8158befe"
      },
      "outputs": [],
      "source": [
        "np.mean(NRMSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.40853091747676434"
      ],
      "metadata": {
        "id": "Ue_og7tpy2Mv"
      },
      "id": "Ue_og7tpy2Mv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y_08"
      ],
      "metadata": {
        "id": "5HuyodYrLBQa"
      },
      "id": "5HuyodYrLBQa"
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
        "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
        "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
        "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
        "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
        "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55']"
      ],
      "metadata": {
        "id": "ZmuBEt7Ate9W"
      },
      "id": "ZmuBEt7Ate9W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_Y_08[feature]\n",
        "y = train_Y_08.loc[:, 'Y_08':]\n",
        "\n",
        "target = test[X.columns]\n",
        "kf = KFold(n_splits = 5, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "tJ6fLJL2jRsi"
      },
      "id": "tJ6fLJL2jRsi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_cat(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `CatBoostRegressor` model.\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'criterion' :  'squared_error',\n",
        "        'n_estimators':trial.suggest_int(\"n_estimators\", 30, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth',1, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split',2,30),        \n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,30),    \n",
        "        'min_weight_fraction_leaf' : trial.suggest_uniform('min_weight_fraction_leaf',0.0, 0.5),\n",
        "        'bootstrap' : True,\n",
        "        'oob_score' : True,\n",
        "        'warm_start' : True,\n",
        "        'verbose' : False\n",
        "    }\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        # objective = 'MultiRMSE',\n",
        "        random_state=42,\n",
        "        **params,\n",
        "    )\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "7J3yGgCOKYTO"
      },
      "id": "7J3yGgCOKYTO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_cat, n_trials=30)"
      ],
      "metadata": {
        "id": "keOEjqzyKYQ3"
      },
      "id": "keOEjqzyKYQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params=study.best_params \n",
        "params['criterion'] = 'squared_error'\n",
        "params['bootstrap'] = True\n",
        "params['oob_score'] = True\n",
        "params['warm_start'] = True\n",
        "params['verbose'] = False"
      ],
      "metadata": {
        "id": "brzIc_7UKYOO"
      },
      "id": "brzIc_7UKYOO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRMSES = []\n",
        "cb_pred = np.zeros(target.shape[0])\n",
        "for i, idx in enumerate(kf.split(X, y)) :\n",
        "    tr_x, tr_y = X.loc[idx[0]], y.loc[idx[0]]\n",
        "    val_x, val_y = X.loc[idx[1]], y.loc[idx[1]]\n",
        "    \n",
        "    cb = RandomForestRegressor(**params)\n",
        "    cb.fit(tr_x, tr_y)\n",
        "    \n",
        "    val_pred = cb.predict(val_x)\n",
        "    NRMSE = mean_squared_error(val_y, val_pred, squared=False)\n",
        "    print(f\"{i + 1} Fold RMSE = {NRMSE}\")\n",
        "    NRMSES.append(NRMSE)\n",
        "    \n",
        "    fold_pred = cb.predict(target) / kf.n_splits\n",
        "    cb_pred += fold_pred"
      ],
      "metadata": {
        "id": "sOEzDjcuKYL2"
      },
      "id": "sOEzDjcuKYL2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(NRMSES)"
      ],
      "metadata": {
        "id": "9P3lschZK2E0"
      },
      "id": "9P3lschZK2E0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.6256107033342393"
      ],
      "metadata": {
        "id": "0fsvhugBdd9q"
      },
      "id": "0fsvhugBdd9q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y_09"
      ],
      "metadata": {
        "id": "0MwXhNSrLEsI"
      },
      "id": "0MwXhNSrLEsI"
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
        "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
        "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
        "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
        "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
        "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55']"
      ],
      "metadata": {
        "id": "KBnZyXmYtsk_"
      },
      "id": "KBnZyXmYtsk_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_Y_09[feature]\n",
        "y = train_Y_09.loc[:, 'Y_09':]\n",
        "\n",
        "target = test[X.columns]\n",
        "kf = KFold(n_splits = 5, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "CylJWmqWLG0_"
      },
      "id": "CylJWmqWLG0_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_cat(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `CatBoostRegressor` model.\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'criterion' :  'squared_error',\n",
        "        'n_estimators':trial.suggest_int(\"n_estimators\", 30, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth',1, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split',2,30),        \n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,30),    \n",
        "        'min_weight_fraction_leaf' : trial.suggest_uniform('min_weight_fraction_leaf',0.0, 0.5),\n",
        "        'bootstrap' : True,\n",
        "        'oob_score' : True,\n",
        "        'warm_start' : True,\n",
        "        'verbose' : False\n",
        "    }\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        # objective = 'MultiRMSE',\n",
        "        random_state=42,\n",
        "        **params,\n",
        "    )\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "Rtc-ClYaLG0m"
      },
      "id": "Rtc-ClYaLG0m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_cat, n_trials=30)"
      ],
      "metadata": {
        "id": "X9aLJhTDLGWE"
      },
      "id": "X9aLJhTDLGWE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params=study.best_params \n",
        "params['criterion'] = 'squared_error'\n",
        "params['bootstrap'] = True\n",
        "params['oob_score'] = True\n",
        "params['warm_start'] = True\n",
        "params['verbose'] = False"
      ],
      "metadata": {
        "id": "TCNJQEaWK4CE"
      },
      "id": "TCNJQEaWK4CE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRMSES = []\n",
        "cb_pred = np.zeros(target.shape[0])\n",
        "for i, idx in enumerate(kf.split(X, y)) :\n",
        "    tr_x, tr_y = X.loc[idx[0]], y.loc[idx[0]]\n",
        "    val_x, val_y = X.loc[idx[1]], y.loc[idx[1]]\n",
        "    \n",
        "    cb = RandomForestRegressor(**params)\n",
        "    cb.fit(tr_x, tr_y)\n",
        "    \n",
        "    val_pred = cb.predict(val_x)\n",
        "    NRMSE = mean_squared_error(val_y, val_pred, squared=False)\n",
        "    print(f\"{i + 1} Fold RMSE = {NRMSE}\")\n",
        "    NRMSES.append(NRMSE)\n",
        "    \n",
        "    fold_pred = cb.predict(target) / kf.n_splits\n",
        "    cb_pred += fold_pred"
      ],
      "metadata": {
        "id": "mqdbX4aMK3_Y"
      },
      "id": "mqdbX4aMK3_Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(NRMSES)"
      ],
      "metadata": {
        "id": "Z_QhCbnMK38-"
      },
      "id": "Z_QhCbnMK38-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.6215526533050436"
      ],
      "metadata": {
        "id": "zazSVPUedgn1"
      },
      "id": "zazSVPUedgn1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y_12"
      ],
      "metadata": {
        "id": "spf28mIqLcCX"
      },
      "id": "spf28mIqLcCX"
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
        "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
        "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
        "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
        "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
        "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55', 'X_56']"
      ],
      "metadata": {
        "id": "qWqI0A_ctt78"
      },
      "id": "qWqI0A_ctt78",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_Y_12[feature]\n",
        "y = train_Y_12.loc[:, 'Y_12':]\n",
        "\n",
        "target = test[X.columns]\n",
        "kf = KFold(n_splits = 5, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "CjxhQZ8BLbzk"
      },
      "id": "CjxhQZ8BLbzk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_cat(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `CatBoostRegressor` model.\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'criterion' :  'squared_error',\n",
        "        'n_estimators':trial.suggest_int(\"n_estimators\", 30, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth',1, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split',2,30),        \n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,30),    \n",
        "        'min_weight_fraction_leaf' : trial.suggest_uniform('min_weight_fraction_leaf',0.0, 0.5),\n",
        "        'bootstrap' : True,\n",
        "        'oob_score' : True,\n",
        "        'warm_start' : True,\n",
        "        'verbose' : False\n",
        "    }\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        # objective = 'MultiRMSE',\n",
        "        random_state=42,\n",
        "        **params,\n",
        "    )\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "-cVvGTxkLbxI"
      },
      "id": "-cVvGTxkLbxI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_cat, n_trials=30)"
      ],
      "metadata": {
        "id": "qE1mvd4XLbui"
      },
      "id": "qE1mvd4XLbui",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params=study.best_params \n",
        "params['criterion'] = 'squared_error'\n",
        "params['bootstrap'] = True\n",
        "params['oob_score'] = True\n",
        "params['warm_start'] = True\n",
        "params['verbose'] = False"
      ],
      "metadata": {
        "id": "yegyKmhaLbsB"
      },
      "id": "yegyKmhaLbsB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRMSES = []\n",
        "cb_pred = np.zeros(target.shape[0])\n",
        "for i, idx in enumerate(kf.split(X, y)) :\n",
        "    tr_x, tr_y = X.loc[idx[0]], y.loc[idx[0]]\n",
        "    val_x, val_y = X.loc[idx[1]], y.loc[idx[1]]\n",
        "    \n",
        "    cb = RandomForestRegressor(**params)\n",
        "    cb.fit(tr_x, tr_y)\n",
        "    \n",
        "    val_pred = cb.predict(val_x)\n",
        "    NRMSE = mean_squared_error(val_y, val_pred, squared=False)\n",
        "    print(f\"{i + 1} Fold RMSE = {NRMSE}\")\n",
        "    NRMSES.append(NRMSE)\n",
        "    \n",
        "    fold_pred = cb.predict(target) / kf.n_splits\n",
        "    cb_pred += fold_pred"
      ],
      "metadata": {
        "id": "NDjB2VexLbpz"
      },
      "id": "NDjB2VexLbpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(NRMSES)"
      ],
      "metadata": {
        "id": "ldgQPBGoLpq9"
      },
      "id": "ldgQPBGoLpq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.6383728120753893"
      ],
      "metadata": {
        "id": "HFvj6AGvdiOr"
      },
      "id": "HFvj6AGvdiOr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y_13"
      ],
      "metadata": {
        "id": "SJt3u1cO4LDq"
      },
      "id": "SJt3u1cO4LDq"
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
        "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
        "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
        "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
        "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
        "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55']"
      ],
      "metadata": {
        "id": "cCG2oVPwb--L"
      },
      "id": "cCG2oVPwb--L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_Y_13[feature]\n",
        "y = train_Y_13.loc[:, 'Y_13':]\n",
        "\n",
        "target = test[X.columns]\n",
        "kf = KFold(n_splits = 5, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "CGay6LKM4SQE"
      },
      "id": "CGay6LKM4SQE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_cat(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `CatBoostRegressor` model.\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'criterion' :  'squared_error',\n",
        "        'n_estimators':trial.suggest_int(\"n_estimators\", 30, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth',1, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split',2,30),        \n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,30),    \n",
        "        'min_weight_fraction_leaf' : trial.suggest_uniform('min_weight_fraction_leaf',0.0, 0.5),\n",
        "        'bootstrap' : True,\n",
        "        'oob_score' : True,\n",
        "        'warm_start' : True,\n",
        "        'verbose' : False\n",
        "    }\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        # objective = 'MultiRMSE',\n",
        "        random_state=42,\n",
        "        **params,\n",
        "    )\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "5tJNtma94SNR"
      },
      "id": "5tJNtma94SNR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_cat, n_trials=30)"
      ],
      "metadata": {
        "id": "h0IYC-6S4SKq"
      },
      "id": "h0IYC-6S4SKq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params=study.best_params \n",
        "params['criterion'] = 'squared_error'\n",
        "params['bootstrap'] = True\n",
        "params['oob_score'] = True\n",
        "params['warm_start'] = True\n",
        "params['verbose'] = False"
      ],
      "metadata": {
        "id": "ATqXuLxr4SIM"
      },
      "id": "ATqXuLxr4SIM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRMSES = []\n",
        "cb_pred = np.zeros(target.shape[0])\n",
        "for i, idx in enumerate(kf.split(X, y)) :\n",
        "    tr_x, tr_y = X.loc[idx[0]], y.loc[idx[0]]\n",
        "    val_x, val_y = X.loc[idx[1]], y.loc[idx[1]]\n",
        "    \n",
        "    cb = RandomForestRegressor(**params)\n",
        "    cb.fit(tr_x, tr_y)\n",
        "    \n",
        "    val_pred = cb.predict(val_x)\n",
        "    NRMSE = mean_squared_error(val_y, val_pred, squared=False)\n",
        "    print(f\"{i + 1} Fold RMSE = {NRMSE}\")\n",
        "    NRMSES.append(NRMSE)\n",
        "    \n",
        "    fold_pred = cb.predict(target) / kf.n_splits\n",
        "    cb_pred += fold_pred"
      ],
      "metadata": {
        "id": "iNe7m1IG4SF4"
      },
      "id": "iNe7m1IG4SF4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(NRMSES)"
      ],
      "metadata": {
        "id": "3Sf0PUSz4a97"
      },
      "id": "3Sf0PUSz4a97",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.6222298082558946"
      ],
      "metadata": {
        "id": "MedP4ghBy92z"
      },
      "id": "MedP4ghBy92z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Y_14"
      ],
      "metadata": {
        "id": "ErcZuWbn4cb0"
      },
      "id": "ErcZuWbn4cb0"
    },
    {
      "cell_type": "code",
      "source": [
        "feature = ['X_01', 'X_02', 'X_03', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10',\n",
        "       'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18', 'X_19',\n",
        "       'X_20', 'X_21', 'X_22', 'X_24', 'X_25', 'X_26', 'X_27', 'X_28', 'X_29',\n",
        "       'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36', 'X_37', 'X_38',\n",
        "       'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45', 'X_46', 'X_49',\n",
        "       'X_50', 'X_51', 'X_52', 'X_53', 'X_54', 'X_55']"
      ],
      "metadata": {
        "id": "pK3iR8nf4luu"
      },
      "id": "pK3iR8nf4luu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_Y_14[feature]\n",
        "y = train_Y_14.loc[:, 'Y_14':]\n",
        "\n",
        "target = test[X.columns]\n",
        "kf = KFold(n_splits = 5, random_state = 42, shuffle = True)"
      ],
      "metadata": {
        "id": "Gmynx8vX4lsp"
      },
      "id": "Gmynx8vX4lsp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_cat(trial):\n",
        "    \"\"\"\n",
        "    Objective function to tune a `CatBoostRegressor` model.\n",
        "    \"\"\"\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    params = {\n",
        "        'criterion' :  'squared_error',\n",
        "        'n_estimators':trial.suggest_int(\"n_estimators\", 30, 400),\n",
        "        'max_depth': trial.suggest_int('max_depth',1, 15),\n",
        "        'min_samples_split': trial.suggest_int('min_samples_split',2,30),        \n",
        "        'min_samples_leaf': trial.suggest_int('min_samples_leaf',1,30),    \n",
        "        'min_weight_fraction_leaf' : trial.suggest_uniform('min_weight_fraction_leaf',0.0, 0.5),\n",
        "        'bootstrap' : True,\n",
        "        'oob_score' : True,\n",
        "        'warm_start' : True,\n",
        "        'verbose' : False\n",
        "    }\n",
        "\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        # objective = 'MultiRMSE',\n",
        "        random_state=42,\n",
        "        **params,\n",
        "    )\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    pred = model.predict(x_test)\n",
        "\n",
        "    rmse = mean_squared_error(y_test, pred, squared=False)\n",
        "\n",
        "\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "-RxBKMjH4lpz"
      },
      "id": "-RxBKMjH4lpz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective_cat, n_trials=30)"
      ],
      "metadata": {
        "id": "cjhpbRiY4lnU"
      },
      "id": "cjhpbRiY4lnU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params=study.best_params \n",
        "params['criterion'] = 'squared_error'\n",
        "params['bootstrap'] = True\n",
        "params['oob_score'] = True\n",
        "params['warm_start'] = True\n",
        "params['verbose'] = False"
      ],
      "metadata": {
        "id": "Enfc0zIA4lkt"
      },
      "id": "Enfc0zIA4lkt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NRMSES = []\n",
        "cb_pred = np.zeros(target.shape[0])\n",
        "for i, idx in enumerate(kf.split(X, y)) :\n",
        "    tr_x, tr_y = X.loc[idx[0]], y.loc[idx[0]]\n",
        "    val_x, val_y = X.loc[idx[1]], y.loc[idx[1]]\n",
        "    \n",
        "    cb = RandomForestRegressor(**params)\n",
        "    cb.fit(tr_x, tr_y)\n",
        "    \n",
        "    val_pred = cb.predict(val_x)\n",
        "    NRMSE = mean_squared_error(val_y, val_pred, squared=False)\n",
        "    print(f\"{i + 1} Fold RMSE = {NRMSE}\")\n",
        "    NRMSES.append(NRMSE)\n",
        "    \n",
        "    fold_pred = cb.predict(target) / kf.n_splits\n",
        "    cb_pred += fold_pred"
      ],
      "metadata": {
        "id": "iK2Xm5Tl4liR"
      },
      "id": "iK2Xm5Tl4liR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(NRMSES)"
      ],
      "metadata": {
        "id": "Fx4-0gVu4lf3"
      },
      "id": "Fx4-0gVu4lf3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.6234742702235347"
      ],
      "metadata": {
        "id": "C0pZ83Fhy_Ix"
      },
      "id": "C0pZ83Fhy_Ix"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gUwMVrw04lde"
      },
      "id": "gUwMVrw04lde",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}