{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "제대로된코드.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW50_EVu_8Qh"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras import optimizers\n",
        "from tensorflow.keras.models import Sequential, Model \n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import keras_metrics as km\n",
        "# from keras import regularizers, optimizers\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLavRlaT_9Cf"
      },
      "source": [
        "data_dir = \"/content/drive/MyDrive/video_data\"\n",
        "img_height , img_width = 64, 64\n",
        "seq_len = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbqgzGXp_9GL",
        "outputId": "b0417ba7-b65d-4198-8be6-88fb5cc4c07b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmXq2Om_9Je"
      },
      "source": [
        "classes = [\"fall\", \"fall_down\", \"grab\", \"swallow\", \"walk\",\"sit\",\"climb\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opzT9QhX_9Md"
      },
      "source": [
        "def frames_extraction(video_path):\n",
        "    frames_list = []\n",
        "     \n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "    frames_step = total_frames//seq_len\n",
        " \n",
        "    for j in range(seq_len):\n",
        "        #here, we set the parameter 1 which is the frame number to the frame (i*frames_step)\n",
        "        vidcap.set(1,j*frames_step)\n",
        "        success,image = vidcap.read()  \n",
        "        #save your image\n",
        "        if success:\n",
        "          image = cv2.resize(image, (img_height, img_width))\n",
        "          frames_list.append(image)\n",
        "        else:\n",
        "          print(\"Defected frame {}\".format(video_path))\n",
        "          break\n",
        "\n",
        "    return frames_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNlh_4g_9Pd"
      },
      "source": [
        "def create_data(input_dir):\n",
        "    X = []\n",
        "    Y = []\n",
        "     \n",
        "    classes_list = os.listdir(input_dir)\n",
        "     \n",
        "    for c in classes_list:\n",
        "        print(c)\n",
        "        files_list = os.listdir(os.path.join(input_dir, c))\n",
        "        for f in files_list:\n",
        "            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
        "            if len(frames) == seq_len:\n",
        "                X.append(frames)\n",
        "             \n",
        "                y = [0]*len(classes)\n",
        "                y[classes.index(c)] = 1\n",
        "                Y.append(y)\n",
        "     \n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If4myzoj_9Sj",
        "outputId": "0ef49ca8-11f8-4d3a-845f-0a06d344f85a"
      },
      "source": [
        "X, Y = create_data(data_dir)\n",
        "X = X/255\n",
        " \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, shuffle=True, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "walk\n",
            "Defected frame /content/drive/MyDrive/video_data/walk/135.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/walk/143.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/walk/101.mov\n",
            "fall_down\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/145.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/143.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/172.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/21.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/26.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/46.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/52.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/57.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/fall_down/81.mov\n",
            "swallow\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/47.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/70.mov\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/79_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/80 (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/81_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/82_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/83_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/swallow/212_1 (online-video-cutter.com).mp4\n",
            "fall\n",
            "grab\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/98_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/99 (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/102_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/103_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/106_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/109_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/110_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/112_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/113 (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/115 (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/116 (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/156 (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/172_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/201_crop (online-video-cutter.com) (1).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/222_crop (online-video-cutter.com).mp4\n",
            "Defected frame /content/drive/MyDrive/video_data/grab/262_1 (online-video-cutter.com).mp4\n",
            "climb\n",
            "sit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcNIK5Kt_9V8",
        "outputId": "90ebfb1d-bd1c-41b9-fd21-e77261156a05"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3),strides = (2,2), return_sequences = True, data_format = \"channels_last\", input_shape = (seq_len, img_height, img_width, 3)))\n",
        "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3),strides = (2,2), return_sequences = True, data_format = \"channels_last\"))\n",
        "model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3),strides = (2,2), return_sequences = True, data_format = \"channels_last\"))\n",
        "model.add(ConvLSTM2D(filters = 128, kernel_size = (3, 3),strides = (2,2), return_sequences = False, data_format = \"channels_last\"))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(7, activation = \"softmax\"))\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv_lst_m2d_12 (ConvLSTM2D) (None, 16, 31, 31, 32)    40448     \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_13 (ConvLSTM2D) (None, 16, 15, 15, 32)    73856     \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_14 (ConvLSTM2D) (None, 16, 7, 7, 64)      221440    \n",
            "_________________________________________________________________\n",
            "conv_lst_m2d_15 (ConvLSTM2D) (None, 3, 3, 128)         885248    \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               590336    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 1,814,919\n",
            "Trainable params: 1,814,919\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUXho8s8_9ZC"
      },
      "source": [
        "def schedular(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * math.exp(0.1*(10-epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "-90KNEiL_9cV",
        "outputId": "59e615d4-5a30-4bf1-dce0-f4e19aa1903b"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(lr=0.0005)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        " \n",
        "earlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "callbacks = tf.keras.callbacks.LearningRateScheduler(schedular)\n",
        " \n",
        "history = model.fit(x = X_train, y = y_train, epochs=20, batch_size = 64, shuffle=True, validation_split=0.3, callbacks=callbacks)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val','accuracy','val_accuracy'])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "17/17 [==============================] - 174s 10s/step - loss: 1.9246 - accuracy: 0.1626 - val_loss: 1.8906 - val_accuracy: 0.2179\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 162s 10s/step - loss: 1.8849 - accuracy: 0.2171 - val_loss: 1.8046 - val_accuracy: 0.2529\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 163s 10s/step - loss: 1.8042 - accuracy: 0.2726 - val_loss: 1.7200 - val_accuracy: 0.2918\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 163s 10s/step - loss: 1.6524 - accuracy: 0.3496 - val_loss: 1.6554 - val_accuracy: 0.3930\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 162s 10s/step - loss: 1.5195 - accuracy: 0.4080 - val_loss: 1.5858 - val_accuracy: 0.4202\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 162s 10s/step - loss: 1.3118 - accuracy: 0.5073 - val_loss: 1.5914 - val_accuracy: 0.4475\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 163s 10s/step - loss: 1.0159 - accuracy: 0.6212 - val_loss: 1.6384 - val_accuracy: 0.4397\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 162s 10s/step - loss: 0.9215 - accuracy: 0.6660 - val_loss: 1.6491 - val_accuracy: 0.4202\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 163s 10s/step - loss: 0.7237 - accuracy: 0.7527 - val_loss: 1.7300 - val_accuracy: 0.4280\n",
            "Epoch 10/50\n",
            " 2/17 [==>...........................] - ETA: 2:27 - loss: 0.4603 - accuracy: 0.8672"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-40af48317542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschedular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQvaOR6l_9f6"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = model.predict(X_test) \n",
        "y_pred = np.argmax(y_pred, axis = 1)\n",
        "y_test = np.argmax(y_test, axis = 1)\n",
        " \n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print('accuracy score : {}'.format(accuracy_score(y_pred, y_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pld5XtLH_9jC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCfk5lqU_9mr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n76YdAYL_9pz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC0rMH9k_9tb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
