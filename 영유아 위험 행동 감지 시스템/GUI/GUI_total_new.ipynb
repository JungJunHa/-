{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b37cc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 16, 31, 31, 32)    40448     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 16, 31, 31, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16, 31, 31, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 16, 15, 15, 32)    73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 15, 15, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 15, 15, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 16, 7, 7, 64)      221440    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 7, 7, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, 3, 3, 128)         885248    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 1,815,943\n",
      "Trainable params: 1,815,431\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import keras_metrics as km\n",
    "# from keras import regularizers, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import math\n",
    "#import vidaug.augmentors as va\n",
    "from sklearn.utils import shuffle\n",
    "new_model=tf.keras.models.load_model('./4aug_epoch30.h5')\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9bbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aceb170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "77f863c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: Microsoft Sound Mapper - Input  INDEX:  0  RATE:  44100 \n",
      "DEVICE: 마이크(Synaptics SmartAudio HD)  INDEX:  1  RATE:  44100 \n",
      "DEVICE: Microsoft Sound Mapper - Output  INDEX:  2  RATE:  44100 \n",
      "DEVICE: 스피커(Synaptics SmartAudio HD)  INDEX:  3  RATE:  44100 \n",
      "DEVICE: 주 사운드 캡처 드라이버  INDEX:  4  RATE:  44100 \n",
      "DEVICE: 마이크(Synaptics SmartAudio HD)  INDEX:  5  RATE:  44100 \n",
      "DEVICE: 주 사운드 드라이버  INDEX:  6  RATE:  44100 \n",
      "DEVICE: 스피커(Synaptics SmartAudio HD)  INDEX:  7  RATE:  44100 \n",
      "DEVICE: 스피커(Synaptics SmartAudio HD)  INDEX:  8  RATE:  48000 \n",
      "DEVICE: 마이크(Synaptics SmartAudio HD)  INDEX:  9  RATE:  48000 \n",
      "DEVICE: Microphone (Conexant HD Audio capture)  INDEX:  10  RATE:  48000 \n",
      "DEVICE: Headphones (Conexant HD Audio headphone)  INDEX:  11  RATE:  48000 \n",
      "DEVICE: Microphone (Conexant HD Audio capture)  INDEX:  12  RATE:  48000 \n",
      "DEVICE: Speakers (Conexant HD Audio output)  INDEX:  13  RATE:  48000 \n",
      "recording...\n",
      "finished recording\n"
     ]
    }
   ],
   "source": [
    "#오디오 기록\n",
    "def audio():\n",
    "    import pyaudio\n",
    "    import wave\n",
    "    po = pyaudio.PyAudio()\n",
    "\n",
    "    for index in range(po.get_device_count()):\n",
    "        desc = po.get_device_info_by_index(index)\n",
    "\n",
    "        # if desc[\"name\"] == \"record\":\n",
    "\n",
    "        print(\"DEVICE: %s  INDEX:  %s  RATE:  %s \" % (desc[\"name\"], index, int(desc[\"defaultSampleRate\"])))\n",
    "\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 5\n",
    "    WAVE_OUTPUT_FILENAME = \"file.wav\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # start Recording\n",
    "    stream = audio.open(format=pyaudio.paInt16,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        input_device_index=1,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"recording...\")\n",
    "\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"finished recording\")\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "#문자 전송\n",
    "def callsms(num):\n",
    "    import sys\n",
    "    from sdk.api.message import Message\n",
    "    from sdk.exceptions import CoolsmsException\n",
    "    api_key = \"NCSIAKAHOQDSODRN\"\n",
    "    api_secret = \"Y42NPXZBUAVLJPO7PIKMWKWNNTHGWQZS\"\n",
    "    ## 4 params(to, from, type, text) are mandatory. must be filled\n",
    "    params = dict()\n",
    "    params['type'] = 'sms' # Message type ( sms, lms, mms, ata )\n",
    "    params['to'] = ent.get()# Recipients Number '01000000000,01000000001'\n",
    "    params['from'] = '01072108042' # Sender number\n",
    "    params['text'] = 'The child is in danger.' # Message\n",
    "    cool = Message(api_key, api_secret)\n",
    "    try:\n",
    "        response = cool.send(params)\n",
    "        print(\"Success Count : %s\" % response['success_count'])\n",
    "        print(\"Error Count : %s\" % response['error_count'])\n",
    "        print(\"Group ID : %s\" % response['group_id'])\n",
    "    except CoolsmsException as e:\n",
    "        print(\"Error Code : %s\" % e.code)\n",
    "        print(\"Error Message : %s\" % e.msg)\n",
    "    sys.exit()\n",
    "\n",
    "#카메라 키기 \n",
    "def camera():\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    thresh = 25\n",
    "    max_diff = 5\n",
    "    img_counter = 0\n",
    "    frame_set = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    a, b, c = None, None, None\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)\n",
    "\n",
    "    if cap.isOpened():\n",
    "        ret, a = cap.read()\n",
    "        ret, b = cap.read()\n",
    "        while ret:\n",
    "            ret, c = cap.read()\n",
    "            draw = c.copy()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            a_gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "            b_gray = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
    "            c_gray = cv2.cvtColor(c, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            diff1 = cv2.absdiff(a_gray, b_gray)\n",
    "            diff2 = cv2.absdiff(b_gray, c_gray)\n",
    "\n",
    "            ret, diff1_t = cv2.threshold(diff1, thresh, 255, cv2.THRESH_BINARY)\n",
    "            ret, diff2_t = cv2.threshold(diff2, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            diff = cv2.bitwise_and(diff1_t, diff2_t)\n",
    "\n",
    "            k = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
    "            diff = cv2.morphologyEx(diff, cv2.MORPH_OPEN, k)\n",
    "\n",
    "            diff_cnt = cv2.countNonZero(diff)\n",
    "            if diff_cnt > max_diff:\n",
    "                nzero = np.nonzero(diff)\n",
    "                cv2.rectangle(draw, (min(nzero[1]), min(nzero[0])),\n",
    "                              (max(nzero[1]), max(nzero[0])), (0, 255, 0), 2)\n",
    "\n",
    "                cv2.putText(draw, \"Motion detected!!\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 255))\n",
    "\n",
    "            cv2.imshow('motion', draw)\n",
    "\n",
    "            a = b\n",
    "            b = c\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if time.time() - start_time >= 0.2:  # <---- Check if 0.2 sec passed\n",
    "                c = cv2.resize(c, (64, 64))\n",
    "                frame_set.append(c)\n",
    "                print(\"{} written!\".format(img_counter))\n",
    "                start_time = time.time()\n",
    "            img_counter += 1\n",
    "            if len(frame_set) >= 17:\n",
    "                del frame_set[0]\n",
    "                \n",
    "            \n",
    "                \n",
    "#오디오 재생코드                \n",
    "def play():\n",
    "  \n",
    "    import pyaudio\n",
    "    import wave\n",
    "    CHUNK = 1024\n",
    "\n",
    "    path = './file.wav'\n",
    "\n",
    "    with wave.open(path, 'rb') as f:\n",
    "        p = pyaudio.PyAudio()\n",
    "        stream = p.open(format=p.get_format_from_width(f.getsampwidth()),\n",
    "                        channels=f.getnchannels(),\n",
    "                        rate=f.getframerate(),\n",
    "                        output=True)\n",
    "\n",
    "        data = f.readframes(CHUNK)\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = f.readframes(CHUNK)\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "        p.terminate()\n",
    "        \n",
    "#GUI구현\n",
    "from tkinter import *\n",
    "import tkinter.messagebox\n",
    "\n",
    "# 창 생성\n",
    "win = Tk() \n",
    "win.geometry(\"1300x700\")\n",
    "win.title(\"AI-KU System\")\n",
    "win.option_add(\"*Font\", \"Georgia 10\")\n",
    "win.configure(bg='#FFEAD0')\n",
    "\n",
    "lab_logo = Label(win)\n",
    "lab_logo.place(x=50, y=50)\n",
    "img_logo = PhotoImage(file='./AI-ku.png', master=win)\n",
    "lab_logo.config(image=img_logo)\n",
    "lab_logo.config(bg='#FFEAD0')\n",
    "\n",
    "\n",
    "# 카메라 라벨\n",
    "lab0 = Label(win)\n",
    "lab0.config(text=\"Turning on camera \")\n",
    "lab0.configure(bg='#FFB399')\n",
    "lab0.place(x=800, y=100)\n",
    "\n",
    "# 버튼\n",
    "btn0 = Button(win, text=\"Camera\")\n",
    "btn0.config(width=30, height=30)\n",
    "btn0.place(x=800, y=130)\n",
    "img0 = PhotoImage(file='./camera.png', master=win)\n",
    "img0 = img0.subsample(25)\n",
    "btn0.config(image=img0)\n",
    "btn0.config(command=camera)\n",
    "\n",
    "# 라벨\n",
    "lab1 = Label(win)\n",
    "lab1.config(text=\"Text will be sent in case of danger. \")\n",
    "lab1.configure(bg='#FFB399')\n",
    "lab1.place(x=800, y=230)\n",
    "\n",
    "# 전화 번호 입력창\n",
    "ent = Entry(win)\n",
    "ent.insert(0, \"Just enter a number.\")\n",
    "def clear(event):\n",
    "    if ent.get() == \"Just enter a number.\":\n",
    "        ent.delete(0, len(ent.get()))\n",
    "ent.bind(\"<Button-1>\", clear)\n",
    "ent.place(x=800, y=260)\n",
    "ent.configure(bg='#FFDAAB')\n",
    "\n",
    "\n",
    "\n",
    "def Msgbox():\n",
    "    tkinter.messagebox.showerror(\"message\", \"Input Error(Number only)\")\n",
    "\n",
    "\n",
    "def alert():\n",
    "    regex = re.compile(\"^[0-9]{11}$\")\n",
    "    if regex.findall(ent.get()):\n",
    "        lab2.config(text=\"Saved~!\")\n",
    "        lab2.configure(bg='#FFB399')\n",
    "    else:\n",
    "        Msgbox()\n",
    "\n",
    "\n",
    "def alert1():\n",
    "    regex = re.compile(\"^[0-9]{11}$\")\n",
    "    if regex.findall(ent.get()):\n",
    "        lab2.config(text=\"Replace Successful~!\")\n",
    "        lab2.configure(bg='#FFB399')\n",
    "    else:\n",
    "        Msgbox()\n",
    "    \n",
    "# 저장 버튼\n",
    "btn = Button(win, text=\"Save\")\n",
    "btn.config(command=alert)\n",
    "btn.config(width=30, height=30)\n",
    "btn.place(x=800, y=300)\n",
    "img = PhotoImage(file='./check.png', master=win)\n",
    "img = img.subsample(25)\n",
    "btn.config(image=img)\n",
    "\n",
    "# 수정 버튼\n",
    "btn_ = Button(win, text=\"Change\")\n",
    "btn_.config(command=alert1)\n",
    "btn_.config(width=30, height=30)\n",
    "btn_.place(x=880, y=300)\n",
    "img_ = PhotoImage(file='./exchange.png', master=win)\n",
    "img_ = img_.subsample(25)\n",
    "btn_.config(image=img_)\n",
    "\n",
    "# 메시지 라벨\n",
    "lab2 = Label(win)\n",
    "lab2.place(x=800, y=350)\n",
    "lab2.configure(bg='#FFEAD0')\n",
    "\n",
    "def button_click(): # This button_click function is used for send button in Tkinter GUI window.\n",
    "    num = ent.get()\n",
    "    sender = callsms(num)\n",
    "    if sender:\n",
    "        showinfo(\"Alert Box\", \"Message Sent Successfully.!\")\n",
    "    else:\n",
    "        showerror(\"Alert Box\", \"Something went wrong. Message was not delivered!\")\n",
    "\n",
    "#q전송 버튼\n",
    "sendBtn = Button(win, text=\"SEND\", command=button_click,fg=\"white\",cursor='hand2')\n",
    "sendBtn.place(x=960,y=300)\n",
    "img_send = PhotoImage(file='./send.png', master=win)\n",
    "img_send = img_send.subsample(25)\n",
    "sendBtn.config(image=img_send)\n",
    "sendBtn.config(width=30, height=30)\n",
    "\n",
    "# 라벨\n",
    "lab3 = Label(win)\n",
    "lab3.config(text=\"Start recording for 5 seconds.\")\n",
    "lab3.configure(bg='#FFB399')\n",
    "lab3.place(x=800, y=450)\n",
    "lab4 = Label(win)\n",
    "lab4.config(text=\"It is broadcast when the child catches dangerous substances \")\n",
    "lab4.configure(bg='#FFB399')\n",
    "lab4.place(x=800, y=470)\n",
    "\n",
    "# 녹음 시작 버튼\n",
    "btn1 = Button(win, text=\"Start\")\n",
    "# btn.config(command=alert)\n",
    "btn1.config(width=30, height=30)\n",
    "btn1.place(x=800, y=520)\n",
    "img1 = PhotoImage(file='./microphone.png', master=win)\n",
    "img1 = img1.subsample(25)\n",
    "btn1.config(image=img1)\n",
    "btn1.config(command=audio)\n",
    "\n",
    "\n",
    "# exit\n",
    "def close_window():\n",
    "\n",
    "    win.destroy()\n",
    "\n",
    "btn2 = Button(win, text=\"Exit\")\n",
    "btn2.config(command=close_window)\n",
    "btn2.place(x=800, y=600)\n",
    "img2 = PhotoImage(file='./exit.png', master=win)\n",
    "img2 = img2.subsample(25)\n",
    "btn2.config(width=30, height=30)\n",
    "btn2.config(image=img2)\n",
    "\n",
    "win.mainloop()  # 창 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca977f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
